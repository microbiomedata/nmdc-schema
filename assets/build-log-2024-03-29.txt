(nmdc-schema-py3.10) mark@mark-NUC10i7FNH:~/gitrepos/berkeley-schema-fy24$ make squeaky-clean all test
Error: open local/gold-study-ids.yaml: no such file or directory
rm -rf project
rm -rf tmp
rm -rf docs/*.md
rm -rf docs/*.html
rm -rf nmdc_schema/nmdc_schema_accepting_legacy_ids*
rm -rf examples/output
rm -rf \
        OmicsProcessing.rq \
        local/mongo_as_nmdc_database.ttl \
        local/mongo_as_nmdc_database_cuire_repaired.ttl \
        local/mongo_as_nmdc_database_rdf_safe.yaml \
        local/mongo_as_nmdc_database_validation.log \
        local/mongo_as_unvalidated_nmdc_database.yaml
#rm -rf local/mixs_regen/mixs_subset_modified.yaml # triggers complete regeneration
rm -rf local/mixs_regen/mixs_subset.yaml
rm -rf local/mixs_regen/mixs_subset_modified.yaml.bak
mkdir -p local/mixs_regen
touch local/mixs_regen/.gitkeep
rm -rf nmdc_schema/*.json
rm -rf nmdc_schema/*.tsv
rm -rf nmdc_schema/*.yaml
poetry run python -m doctest -v nmdc_schema/migrators/*.py
2 items had no tests:
    helpers
    helpers.load_yaml_asset
0 tests in 2 items.
0 passed and 0 failed.
Test passed.
1 items had no tests:
    __init__
0 tests in 1 items.
0 passed and 0 failed.
Test passed.
6 items had no tests:
    migrator_base
    migrator_base.MigratorBase
    migrator_base.MigratorBase.__init__
    migrator_base.MigratorBase.get_destination_version
    migrator_base.MigratorBase.get_origin_version
    migrator_base.MigratorBase.upgrade
0 tests in 6 items.
0 passed and 0 failed.
Test passed.
Trying:
    m = Migrator()
Expecting nothing
No adapter was specified. Migration capability will be limited.
ok
Trying:
    m.replace_doi_field_with_award_dois_list_field({'id': 123})  # no `doi` field
Expecting:
    {'id': 123}
ok
Trying:
    m.replace_doi_field_with_award_dois_list_field({'id': 123, 'doi': {'has_raw_value': 'not-a-url'}})
Expecting:
    {'id': 123}
ok
Trying:
    m.replace_doi_field_with_award_dois_list_field(
        {'id': 123, 'doi': {'has_raw_value': 'https://example.com/10.other_stuff'}}
    )
Expecting:
    {'id': 123, 'award_dois': ['doi:10.other_stuff']}
ok
3 items had no tests:
    migrator_from_7_7_2_to_7_8_0
    migrator_from_7_7_2_to_7_8_0.Migrator
    migrator_from_7_7_2_to_7_8_0.Migrator.upgrade
1 items passed all tests:
   4 tests in migrator_from_7_7_2_to_7_8_0.Migrator.replace_doi_field_with_award_dois_list_field
4 tests in 4 items.
4 passed and 0 failed.
Test passed.
Trying:
    m = Migrator()
Expecting nothing
No adapter was specified. Migration capability will be limited.
ok
Trying:
    m.rename_sample_mass_field({'id': 123})  # no `sample_mass` field
Expecting:
    {'id': 123}
ok
Trying:
    m.rename_sample_mass_field({'id': 123, 'sample_mass': 456})  # test: renames field and preserves value
Expecting:
    {'id': 123, 'input_mass': 456}
ok
Trying:
    m = Migrator()
Expecting nothing
No adapter was specified. Migration capability will be limited.
ok
Trying:
    m.standardize_letter_casing_of_gold_biosample_identifiers({'id': 123})
Expecting:
    {'id': 123, 'gold_biosample_identifiers': []}
ok
Trying:
    m.standardize_letter_casing_of_gold_biosample_identifiers(
        {'id': 123, 'gold_biosample_identifiers': ['GOLD:foo', 'gold:bar']}
    )
Expecting:
    {'id': 123, 'gold_biosample_identifiers': ['gold:foo', 'gold:bar']}
ok
Trying:
    m = Migrator()
Expecting nothing
No adapter was specified. Migration capability will be limited.
ok
Trying:
    m.standardize_letter_casing_of_gold_identifiers(['GOLD:prefix_was_uppercase'])
Expecting:
    ['gold:prefix_was_uppercase']
ok
Trying:
    m.standardize_letter_casing_of_gold_identifiers(['gold:prefix_was_lowercase'])
Expecting:
    ['gold:prefix_was_lowercase']
ok
Trying:
    m.standardize_letter_casing_of_gold_identifiers(['Gold:prefix_remains_mixed_case'])
Expecting:
    ['Gold:prefix_remains_mixed_case']
ok
Trying:
    m.standardize_letter_casing_of_gold_identifiers(['GOLD:preserves_this:but_not_this'])
Expecting:
    ['gold:preserves_this']
ok
Trying:
    m = Migrator()
Expecting nothing
No adapter was specified. Migration capability will be limited.
ok
Trying:
    m.standardize_letter_casing_of_gold_sequencing_project_identifiers({'id': 123})
Expecting:
    {'id': 123, 'gold_sequencing_project_identifiers': []}
ok
Trying:
    m.standardize_letter_casing_of_gold_sequencing_project_identifiers(
        {'id': 123, 'gold_sequencing_project_identifiers': ['GOLD:foo', 'gold:bar']}
    )
Expecting:
    {'id': 123, 'gold_sequencing_project_identifiers': ['gold:foo', 'gold:bar']}
ok
Trying:
    m = Migrator()
Expecting nothing
No adapter was specified. Migration capability will be limited.
ok
Trying:
    m.standardize_letter_casing_of_gold_study_identifier({'id': 123})
Expecting:
    {'id': 123, 'gold_study_identifiers': []}
ok
Trying:
    m.standardize_letter_casing_of_gold_study_identifier(
        {'id': 123, 'gold_study_identifiers': ['GOLD:foo', 'gold:bar']}
    )
Expecting:
    {'id': 123, 'gold_study_identifiers': ['gold:foo', 'gold:bar']}
ok
3 items had no tests:
    migrator_from_7_8_0_to_8_0_0
    migrator_from_7_8_0_to_8_0_0.Migrator
    migrator_from_7_8_0_to_8_0_0.Migrator.upgrade
5 items passed all tests:
   3 tests in migrator_from_7_8_0_to_8_0_0.Migrator.rename_sample_mass_field
   3 tests in migrator_from_7_8_0_to_8_0_0.Migrator.standardize_letter_casing_of_gold_biosample_identifiers
   5 tests in migrator_from_7_8_0_to_8_0_0.Migrator.standardize_letter_casing_of_gold_identifiers
   3 tests in migrator_from_7_8_0_to_8_0_0.Migrator.standardize_letter_casing_of_gold_sequencing_project_identifiers
   3 tests in migrator_from_7_8_0_to_8_0_0.Migrator.standardize_letter_casing_of_gold_study_identifier
17 tests in 8 items.
17 passed and 0 failed.
Test passed.
Trying:
    m = Migrator()
Expecting nothing
No adapter was specified. Migration capability will be limited.
ok
Trying:
    m.force_research_study_study_category({'id': 123})  # field doesn't exist yet
Expecting:
    {'id': 123, 'study_category': 'research_study'}
ok
Trying:
    m.force_research_study_study_category({'id': 123, 'study_category': 'preserve_me'})  # field already exists
Expecting:
    {'id': 123, 'study_category': 'preserve_me'}
ok
3 items had no tests:
    migrator_from_8_0_to_8_1
    migrator_from_8_0_to_8_1.Migrator
    migrator_from_8_0_to_8_1.Migrator.upgrade
1 items passed all tests:
   3 tests in migrator_from_8_0_to_8_1.Migrator.force_research_study_study_category
3 tests in 4 items.
3 passed and 0 failed.
Test passed.
Trying:
    m = Migrator()
Expecting nothing
No adapter was specified. Migration capability will be limited.
ok
Trying:
    m.fix_ess_dive({'id': 1, 'ess_dive_datasets': ['a']})  # test: a single DOI
Expecting:
    {'id': 1, 'ess_dive_datasets': ['a'], 'associated_dois': [{'doi_value': 'a', 'doi_category': 'dataset_doi', 'doi_provider': 'ess_dive'}]}
ok
Trying:
    m = Migrator()
Expecting nothing
No adapter was specified. Migration capability will be limited.
ok
Trying:
    m.fix_massive({'id': 123})
Expecting:
    {'id': 123, 'associated_dois': []}
ok
Trying:
    m.fix_massive({'id': 123, 'massive_study_identifiers': ['not-the-one']})
Expecting:
    {'id': 123, 'massive_study_identifiers': ['not-the-one'], 'associated_dois': []}
ok
Trying:
    m.fix_massive({'id': 123, 'massive_study_identifiers': ['MASSIVE:MSV000090886']})  # this is the one!
Expecting:
    {'id': 123, 'associated_dois': [{'doi_value': 'doi:10.25345/C58K7520G', 'doi_category': 'dataset_doi', 'doi_provider': 'massive'}]}
ok
Trying:
    m = Migrator()
Expecting nothing
No adapter was specified. Migration capability will be limited.
ok
Trying:
    m.fix_pub_dois({'id': 1, 'publication_dois': ['a']})  # test: a single DOI
Expecting:
    {'id': 1, 'publication_dois': ['a'], 'associated_dois': [{'doi_value': 'a', 'doi_category': 'publication_doi'}]}
ok
Trying:
    m = Migrator()
Expecting nothing
No adapter was specified. Migration capability will be limited.
ok
Trying:
    m.process_doi({'id': 123}, [{'id': 123, 'doi': 'a', 'doi_prov': 'b'}], 'c')  # `id` matches
Expecting:
    {'id': 123, 'associated_dois': [{'doi_value': 'a', 'doi_category': 'c', 'doi_provider': 'b'}]}
ok
Trying:
    m.process_doi({'id': 123}, [{'id': 555, 'doi': 'a', 'doi_prov': 'b'}], 'c')  # `id` does not match
Expecting:
    {'id': 123}
ok
Trying:
    m.process_doi(
        {'id': 123, 'associated_dois': [{'doi_value': 'x', 'doi_category': 'y', 'doi_provider': 'z'}]},
        [{'id': 123, 'doi': 'a', 'doi_prov': 'b'}], 'c'
    )  # study already has an `associated_dois` field
Expecting:
    {'id': 123, 'associated_dois': [{'doi_value': 'x', 'doi_category': 'y', 'doi_provider': 'z'}, {'doi_value': 'a', 'doi_category': 'c', 'doi_provider': 'b'}]}
ok
Trying:
    m = Migrator()
Expecting nothing
No adapter was specified. Migration capability will be limited.
ok
Trying:
    m.remove_doi_slots({'id': 123, 'associated_dois': []})  # empty `associated_dois` list gets removed
Expecting:
    {'id': 123}
ok
Trying:
    m.remove_doi_slots({
       'id': 123,
       'associated_dois': [{'doi_value': 'a', 'doi_category': 'c', 'doi_provider': 'b'}],
       'publication_dois': ['a'],
    })  # lists in which all values match an `associated_dois[].doi_value` get removed
Expecting:
    {'id': 123, 'associated_dois': [{'doi_value': 'a', 'doi_category': 'c', 'doi_provider': 'b'}]}
ok
4 items had no tests:
    migrator_from_8_1_to_9_0
    migrator_from_8_1_to_9_0.Migrator
    migrator_from_8_1_to_9_0.Migrator.fix_award_dois
    migrator_from_8_1_to_9_0.Migrator.upgrade
5 items passed all tests:
   2 tests in migrator_from_8_1_to_9_0.Migrator.fix_ess_dive
   4 tests in migrator_from_8_1_to_9_0.Migrator.fix_massive
   2 tests in migrator_from_8_1_to_9_0.Migrator.fix_pub_dois
   4 tests in migrator_from_8_1_to_9_0.Migrator.process_doi
   3 tests in migrator_from_8_1_to_9_0.Migrator.remove_doi_slots
15 tests in 9 items.
15 passed and 0 failed.
Test passed.
Trying:
    m = Migrator()
Expecting nothing
No adapter was specified. Migration capability will be limited.
ok
Trying:
    m.move_doi_from_websites({'id': 123, 'websites': ['a', 'https://doi.org/10.25982/109073.30/1895615'], 'associated_dois':
        [{'doi_value': 'j', 'doi_provider': 'k', 'doi_category': 'i'}]})
Expecting:
    {'id': 123, 'websites': ['a'], 'associated_dois': [{'doi_value': 'j', 'doi_provider': 'k', 'doi_category': 'i'}, {'doi_value': 'doi:10.25982/109073.30/1895615', 'doi_category': 'dataset_doi', 'doi_provider': 'kbase'}]}
ok
3 items had no tests:
    migrator_from_9_1_to_9_2
    migrator_from_9_1_to_9_2.Migrator
    migrator_from_9_1_to_9_2.Migrator.upgrade
1 items passed all tests:
   2 tests in migrator_from_9_1_to_9_2.Migrator.move_doi_from_websites
2 tests in 4 items.
2 passed and 0 failed.
Test passed.
Trying:
    m = Migrator()
Expecting nothing
No adapter was specified. Migration capability will be limited.
ok
Trying:
    m.move_extraction_qc_status({'id': 123, 'quality_control_report': {'status': 'pass'}})
Expecting:
    {'id': 123, 'qc_status': 'pass'}
ok
Trying:
    m.move_extraction_qc_status({'id': 123, 'quality_control_report': {'status': 'fail'}})
Expecting:
    {'id': 123, 'qc_status': 'fail'}
ok
Trying:
    m.move_extraction_qc_status({'id': 123, 'quality_control_report': {'status': 'pass', 'name': 'n'}})
Expecting:
    {'id': 123, 'qc_status': 'pass'}
ok
Trying:
    m.move_extraction_qc_status({'id': 123, 'quality_control_report': {'status': 'fail', 'name': 'n'}})
Expecting:
    {'id': 123, 'qc_status': 'fail'}
ok
Trying:
    m.move_extraction_qc_status({'id': 123, 'quality_control_report': {'name': 'n'}})
Expecting:
    {'id': 123}
ok
Trying:
    m.move_extraction_qc_status({'id': 123, 'quality_control_report': {}})
Expecting:
    {'id': 123}
ok
3 items had no tests:
    migrator_from_9_3_to_10_0
    migrator_from_9_3_to_10_0.Migrator
    migrator_from_9_3_to_10_0.Migrator.upgrade
1 items passed all tests:
   7 tests in migrator_from_9_3_to_10_0.Migrator.move_extraction_qc_status
7 tests in 4 items.
7 passed and 0 failed.
Test passed.
Trying:
    m = Migrator()  # creates a class instance on which we can call this function (i.e. this method)
Expecting nothing
No adapter was specified. Migration capability will be limited.
ok
Trying:
    m.allow_multiple_names({'id': 123, 'name': 'My project'})  # test: transfers existing name to `names` list
Expecting:
    {'id': 123, 'names': ['My project']}
ok
Trying:
    m.allow_multiple_names({'id': 123, 'name': 'My project', 'foo': 'bar'})  # test: preserves other keys
Expecting:
    {'id': 123, 'foo': 'bar', 'names': ['My project']}
ok
3 items had no tests:
    migrator_from_A_B_C_to_X_Y_Z
    migrator_from_A_B_C_to_X_Y_Z.Migrator
    migrator_from_A_B_C_to_X_Y_Z.Migrator.upgrade
1 items passed all tests:
   3 tests in migrator_from_A_B_C_to_X_Y_Z.Migrator.allow_multiple_names
3 tests in 4 items.
3 passed and 0 failed.
Test passed.
Trying:
    m = Migrator()
Expecting nothing
No adapter was specified. Migration capability will be limited.
ok
Trying:
    m.add_type_slot_with_class_uri({'id': 123, 'collection_date': {'has_raw_value': '2017-05-09'}}, 'nmdc:Biosample', {'collection_date': 'nmdc:TimestampValue'})
Expecting:
    {'id': 123, 'collection_date': {'has_raw_value': '2017-05-09', 'type': 'nmdc:TimestampValue'}, 'type': 'nmdc:Biosample'}
ok
Trying:
    m.add_type_slot_with_class_uri({'id': 567, 'type': 'nmdc:DataGeneration'}, 'nmdc:DataGeneration')
Expecting:
    {'id': 567, 'type': 'nmdc:DataGeneration'}
ok
Trying:
    m.add_type_slot_with_class_uri({'id': 567, 'env_broad_scale': {'term': {'id': 'ENVO:1234'}}}, 'nmdc:Biosample', {'env_broad_scale': 'nmdc:ControlledIdentifiedTermValue'})
Expecting:
    {'id': 567, 'env_broad_scale': {'term': {'id': 'ENVO:1234', 'type': 'nmdc:OntologyClass'}, 'type': 'nmdc:ControlledIdentifiedTermValue'}, 'type': 'nmdc:Biosample'}
ok
Trying:
    m.add_type_slot_with_class_uri({'id': 456}, 'nmdc:NomAnalysis')
Expecting:
    {'id': 456, 'type': 'nmdc:NomAnalysis'}
ok
4 items had no tests:
    migrator_from_X_to_PR10
    migrator_from_X_to_PR10.Migrator
    migrator_from_X_to_PR10.Migrator.add_type_to_inlined_classes
    migrator_from_X_to_PR10.Migrator.upgrade
1 items passed all tests:
   5 tests in migrator_from_X_to_PR10.Migrator.add_type_slot_with_class_uri
5 tests in 5 items.
5 passed and 0 failed.
Test passed.
Trying:
    m = Migrator()
Expecting nothing
No adapter was specified. Migration capability will be limited.
ok
Trying:
    m.move_relevant_protocols_to_protocol_link({'id': 123, 'relevant_protocols': ['www.ex1.org', 'www.ex2.gov']})
Expecting:
    {'id': 123, 'protocol_link': [{'url': 'www.ex1.org', 'type': 'nmdc:Protocol'}, {'url': 'www.ex2.gov', 'type': 'nmdc:Protocol'}]}
ok
Trying:
    m.move_relevant_protocols_to_protocol_link({'id': 123, 'relevant_protocols': ['www.ex3.org']})
Expecting:
    {'id': 123, 'protocol_link': [{'url': 'www.ex3.org', 'type': 'nmdc:Protocol'}]}
ok
3 items had no tests:
    migrator_from_X_to_PR21
    migrator_from_X_to_PR21.Migrator
    migrator_from_X_to_PR21.Migrator.upgrade
1 items passed all tests:
   3 tests in migrator_from_X_to_PR21.Migrator.move_relevant_protocols_to_protocol_link
3 tests in 4 items.
3 passed and 0 failed.
Test passed.
Trying:
    m = Migrator()
Expecting nothing
No adapter was specified. Migration capability will be limited.
ok
Trying:
    m.standardize_execution_resource({'id': 123, 'execution_resource': 'LANL B-div'})
Expecting:
    {'id': 123, 'execution_resource': 'LANL-B-div'}
ok
Trying:
    m.standardize_execution_resource({'id': 234, 'execution_resource': 'NERSC - Cori'})
Expecting:
    {'id': 234, 'execution_resource': 'NERSC-Cori'}
ok
3 items had no tests:
    migrator_from_X_to_PR23
    migrator_from_X_to_PR23.Migrator
    migrator_from_X_to_PR23.Migrator.upgrade
1 items passed all tests:
   3 tests in migrator_from_X_to_PR23.Migrator.standardize_execution_resource
3 tests in 4 items.
3 passed and 0 failed.
Test passed.
3 items had no tests:
    migrator_from_X_to_PR2_and_PR24
    migrator_from_X_to_PR2_and_PR24.Migrator
    migrator_from_X_to_PR2_and_PR24.Migrator.upgrade
0 tests in 3 items.
0 passed and 0 failed.
Test passed.
Trying:
    m = Migrator()
Expecting nothing
No adapter was specified. Migration capability will be limited.
ok
Trying:
    m.specify_data_gen_type({'id': 123, 'analyte_category': 'nom', 'type': 'nmdc:DataGeneration'})
Expecting:
    {'id': 123, 'analyte_category': 'nom', 'type': 'nmdc:MassSpectrometry'}
ok
Trying:
    m.specify_data_gen_type({'id': 234, 'analyte_category': 'metagenome', 'type': 'nmdc:DataGeneration'})
Expecting:
    {'id': 234, 'analyte_category': 'metagenome', 'type': 'nmdc:NucleotideSequencing'}
ok
3 items had no tests:
    migrator_from_X_to_PR3
    migrator_from_X_to_PR3.Migrator
    migrator_from_X_to_PR3.Migrator.upgrade
1 items passed all tests:
   3 tests in migrator_from_X_to_PR3.Migrator.specify_data_gen_type
3 tests in 4 items.
3 passed and 0 failed.
Test passed.
Trying:
    m = Migrator()
Expecting nothing
No adapter was specified. Migration capability will be limited.
ok
Trying:
    m.update_analyte_category_from_omics_type({'id': 123, 'omics_type': {'has_raw_value': 'Organic Matter Characterization'}})
Expecting:
    {'id': 123, 'analyte_category': 'nom'}
ok
3 items had no tests:
    migrator_from_X_to_PR4
    migrator_from_X_to_PR4.Migrator
    migrator_from_X_to_PR4.Migrator.upgrade
1 items passed all tests:
   2 tests in migrator_from_X_to_PR4.Migrator.update_analyte_category_from_omics_type
2 tests in 4 items.
2 passed and 0 failed.
Test passed.
Trying:
    m = Migrator()
Expecting nothing
No adapter was specified. Migration capability will be limited.
ok
Trying:
    m.move_part_of_to_associated_studies({'id': 123, 'part_of': ['gold:Gs0114663', 'nmdc:sty-55-xxx']})
Expecting:
    {'id': 123, 'associated_studies': ['gold:Gs0114663', 'nmdc:sty-55-xxx']}
ok
Trying:
    m.move_part_of_to_associated_studies({'id': 123, 'part_of': []})  # `part_of` list is empty
Expecting:
    {'id': 123}
ok
Trying:
    m.move_part_of_to_associated_studies({'id': 123})  # lacks `part_of` key
Expecting:
    {'id': 123}
ok
3 items had no tests:
    migrator_from_X_to_PR53
    migrator_from_X_to_PR53.Migrator
    migrator_from_X_to_PR53.Migrator.upgrade
1 items passed all tests:
   4 tests in migrator_from_X_to_PR53.Migrator.move_part_of_to_associated_studies
4 tests in 4 items.
4 passed and 0 failed.
Test passed.
poetry run python -m doctest -v nmdc_schema/migrators/adapters/*.py
10 items had no tests:
    adapter_base
    adapter_base.AdapterBase
    adapter_base.AdapterBase.create_collection
    adapter_base.AdapterBase.delete_collection
    adapter_base.AdapterBase.delete_documents_having_value_in_field
    adapter_base.AdapterBase.get_document_having_one_of_values_in_field
    adapter_base.AdapterBase.get_document_having_value_in_field
    adapter_base.AdapterBase.insert_document
    adapter_base.AdapterBase.process_each_document
    adapter_base.AdapterBase.rename_collection
0 tests in 10 items.
0 passed and 0 failed.
Test passed.
Trying:
    database = {
      "thing_set": [
        {"id": "111", "foo": "bar"},
        {"id": "222", "foo": "baz"},
        {"id": "333", "foo": "qux"}
      ]
    }
Expecting nothing
ok
Trying:
    da = DictionaryAdapter(database)
Expecting nothing
ok
Trying:
    da.create_collection("thing_set")
Expecting nothing
ok
Trying:
    "thing_set" in database
Expecting:
    True
ok
Trying:
    len(database["thing_set"])  # existing collection will retain existing contents
Expecting:
    3
ok
Trying:
    da.create_collection("item_set")
Expecting nothing
ok
Trying:
    "item_set" in database
Expecting:
    True
ok
Trying:
    len(database["item_set"])  # new collection will be empty
Expecting:
    0
ok
Trying:
    database = {
      "thing_set": [
        {"id": "111", "foo": "bar"},
        {"id": "222", "foo": "baz"},
        {"id": "333", "foo": "qux"}
      ]
    }
Expecting nothing
ok
Trying:
    da = DictionaryAdapter(database)
Expecting nothing
ok
Trying:
    da.delete_collection("thing_set")
Expecting nothing
ok
Trying:
    "thing_set" in database
Expecting:
    False
ok
Trying:
    database = {
      "thing_set": [
        {"id": "111", "foo": "bar"},
        {"id": "222", "foo": "baz"},
        {"id": "222", "foo": "blue"},  # same id, so that we can...
        {"id": "222", "foo": "blue"},  # ...test deleting multiple.
        {"id": "333", "foo": "qux"}
      ]
    }
Expecting nothing
ok
Trying:
    da = DictionaryAdapter(database)
Expecting nothing
ok
Trying:
    len(database["thing_set"])
Expecting:
    5
ok
Trying:
    da.delete_documents_having_value_in_field("thing_set", "id", "no_such_value")
Expecting:
    0
ok
Trying:
    da.delete_documents_having_value_in_field("thing_set", "no_such_field", "111")
Expecting:
    0
ok
Trying:
    len(database["thing_set"])
Expecting:
    5
ok
Trying:
    da.delete_documents_having_value_in_field("thing_set", "id", "222")  # deletes 3 documents
Expecting:
    3
ok
Trying:
    len(database["thing_set"])
Expecting:
    2
ok
Trying:
    da.delete_documents_having_value_in_field("thing_set", "foo", "qux")
Expecting:
    1
ok
Trying:
    len(database["thing_set"])
Expecting:
    1
ok
Trying:
    database = {
      "thing_set": [
        {"id": "111", "foo": "bar"},
        {"id": "222", "foo": "baz"},
        {"id": "333", "foo": "qux"}
      ]
    }
Expecting nothing
ok
Trying:
    da = DictionaryAdapter(database)
Expecting nothing
ok
Trying:
    da.get_document_having_one_of_values_in_field("thing_set", "id", ["221", "222", "223"])
Expecting:
    {'id': '222', 'foo': 'baz'}
ok
Trying:
    da.get_document_having_one_of_values_in_field("thing_set", "foo", ["baa", "baz", "bab"])
Expecting:
    {'id': '222', 'foo': 'baz'}
ok
Trying:
    da.get_document_having_one_of_values_in_field("thing_set", "id", ["no_such_value"]) is None
Expecting:
    True
ok
Trying:
    da.get_document_having_one_of_values_in_field("thing_set", "foo", []) is None  # no values to match with
Expecting:
    True
ok
Trying:
    database = {
      "thing_set": [
        {"id": "111", "foo": "bar"},
        {"id": "222", "foo": "baz"},
        {"id": "333", "foo": "qux"}
      ]
    }
Expecting nothing
ok
Trying:
    da = DictionaryAdapter(database)
Expecting nothing
ok
Trying:
    da.get_document_having_value_in_field("thing_set", "id", "222")
Expecting:
    {'id': '222', 'foo': 'baz'}
ok
Trying:
    da.get_document_having_value_in_field("thing_set", "foo", "baz")
Expecting:
    {'id': '222', 'foo': 'baz'}
ok
Trying:
    da.get_document_having_value_in_field("thing_set", "id", "no_such_value") is None
Expecting:
    True
ok
Trying:
    da.get_document_having_value_in_field("thing_set", "no_such_field", "111") is None
Expecting:
    True
ok
Trying:
    database = {
      "thing_set": [
        {"id": "111", "foo": "bar"},
        {"id": "222", "foo": "baz"},
        {"id": "333", "foo": "qux"}
      ]
    }
Expecting nothing
ok
Trying:
    da = DictionaryAdapter(database)
Expecting nothing
ok
Trying:
    da.insert_document("thing_set", {"id": "444", "foo": "dee"})
Expecting nothing
ok
Trying:
    database["thing_set"][-1]  # gets last item in list
Expecting:
    {'id': '444', 'foo': 'dee'}
ok
Trying:
    def capitalize_foo_value(document: dict) -> dict:
        document["foo"] = document["foo"].upper()
        return document
Expecting nothing
ok
Trying:
    database = {
      "thing_set": [
        {"id": "111", "foo": "bar"},
        {"id": "222", "foo": "baz"},
        {"id": "333", "foo": "qux"}
      ]
    }
Expecting nothing
ok
Trying:
    da = DictionaryAdapter(database)
Expecting nothing
ok
Trying:
    da.process_each_document("thing_set", [capitalize_foo_value])
Expecting nothing
ok
Trying:
    database["thing_set"][0]
Expecting:
    {'id': '111', 'foo': 'BAR'}
ok
Trying:
    database["thing_set"][1]
Expecting:
    {'id': '222', 'foo': 'BAZ'}
ok
Trying:
    da.process_each_document("missing_set", [capitalize_foo_value])  # non-existent collection does not trigger an exception
Expecting nothing
ok
Trying:
    database = {
      "thing_set": [
        {"id": "111", "foo": "bar"},
        {"id": "222", "foo": "baz"},
        {"id": "333", "foo": "qux"}
      ]
    }
Expecting nothing
ok
Trying:
    da = DictionaryAdapter(database)
Expecting nothing
ok
Trying:
    da.rename_collection("thing_set", "item_set")
Expecting nothing
ok
Trying:
    "thing_set" in database
Expecting:
    False
ok
Trying:
    "item_set" in database
Expecting:
    True
ok
3 items had no tests:
    dictionary_adapter
    dictionary_adapter.DictionaryAdapter
    dictionary_adapter.DictionaryAdapter.__init__
8 items passed all tests:
   8 tests in dictionary_adapter.DictionaryAdapter.create_collection
   4 tests in dictionary_adapter.DictionaryAdapter.delete_collection
  10 tests in dictionary_adapter.DictionaryAdapter.delete_documents_having_value_in_field
   6 tests in dictionary_adapter.DictionaryAdapter.get_document_having_one_of_values_in_field
   6 tests in dictionary_adapter.DictionaryAdapter.get_document_having_value_in_field
   4 tests in dictionary_adapter.DictionaryAdapter.insert_document
   7 tests in dictionary_adapter.DictionaryAdapter.process_each_document
   5 tests in dictionary_adapter.DictionaryAdapter.rename_collection
50 tests in 11 items.
50 passed and 0 failed.
Test passed.
11 items had no tests:
    mongo_adapter
    mongo_adapter.MongoAdapter
    mongo_adapter.MongoAdapter.__init__
    mongo_adapter.MongoAdapter.create_collection
    mongo_adapter.MongoAdapter.delete_collection
    mongo_adapter.MongoAdapter.delete_documents_having_value_in_field
    mongo_adapter.MongoAdapter.get_document_having_one_of_values_in_field
    mongo_adapter.MongoAdapter.get_document_having_value_in_field
    mongo_adapter.MongoAdapter.insert_document
    mongo_adapter.MongoAdapter.process_each_document
    mongo_adapter.MongoAdapter.rename_collection
0 tests in 11 items.
0 passed and 0 failed.
Test passed.
12 items had no tests:
    test_mongo_adapter
    test_mongo_adapter.TestMongoAdapter
    test_mongo_adapter.TestMongoAdapter.setUp
    test_mongo_adapter.TestMongoAdapter.tearDown
    test_mongo_adapter.TestMongoAdapter.test_create_collection
    test_mongo_adapter.TestMongoAdapter.test_delete_collection
    test_mongo_adapter.TestMongoAdapter.test_delete_documents_having_value_in_field
    test_mongo_adapter.TestMongoAdapter.test_get_document_having_one_of_values_in_field
    test_mongo_adapter.TestMongoAdapter.test_get_document_having_value_in_field
    test_mongo_adapter.TestMongoAdapter.test_insert_document
    test_mongo_adapter.TestMongoAdapter.test_process_each_document
    test_mongo_adapter.TestMongoAdapter.test_rename_collection
0 tests in 12 items.
0 passed and 0 failed.
Test passed.
poetry run python -m doctest -v nmdc_schema/migrators/cli/*.py
Trying:
    validate_version_identifier(None, None, "1.2.3")
Expecting:
    '1.2.3'
ok
Trying:
    validate_version_identifier(None, None, "1.2.")  # doesn't end with a number
Expecting:
    Traceback (most recent call last):
    ...
    click.exceptions.BadParameter: Invalid format.
ok
Trying:
    validate_version_identifier(None, None, "1.2")
Expecting:
    '1.2'
ok
Trying:
    validate_version_identifier(None, None, "123.456.789")
Expecting:
    '123.456.789'
ok
Trying:
    validate_version_identifier(None, None, "123.456.789.1")  # 4 parts
Expecting:
    Traceback (most recent call last):
    ...
    click.exceptions.BadParameter: Invalid format.
ok
Trying:
    validate_version_identifier(None, None, "123")
Expecting:
    '123'
ok
2 items had no tests:
    create_migrator
    create_migrator.click_option_validator
1 items passed all tests:
   6 tests in create_migrator.validate_version_identifier
6 tests in 3 items.
6 passed and 0 failed.
Test passed.
1 items had no tests:
    __init__
0 tests in 1 items.
0 passed and 0 failed.
Test passed.
poetry run gen-linkml \
        --format yaml \
        --mergeimports \
        --metadata \
        --no-materialize-attributes \
        --no-materialize-patterns \
        --useuris \
        --output nmdc_schema/nmdc_schema_accepting_legacy_ids.yaml src/schema/nmdc.yaml
nmdc_schema/nmdc_schema_accepting_legacy_ids.yaml
grep "^'" assets/yq-for-nmdc_schema_accepting_legacy_ids.txt | while IFS= read -r line ; do echo $line ; eval yq -i $line nmdc_schema/nmdc_schema_accepting_legacy_ids.yaml ; done
'(.classes[] | select(.name == "Biosample") | .slot_usage.id.pattern) = ".*"'
'(.classes[] | select(.name == "Biosample") | .slot_usage.part_of.pattern) = ".*"'
'(.classes[] | select(.name == "Biosample") | .slot_usage.id.structured_pattern.syntax) = ".*"'
'(.classes[] | select(.name == "DataObject") | .slot_usage.id.pattern) = ".*"'
'(.classes[] | select(.name == "DataObject") | .slot_usage.id.structured_pattern.syntax) = ".*"'
'(.classes[] | select(.name == "MagsAnalysisActivity") | .slot_usage.id.pattern) = ".*"'
'(.classes[] | select(.name == "MagsAnalysisActivity") | .slot_usage.id.structured_pattern.syntax) = ".*"'
'(.classes[] | select(.name == "MetabolomicsAnalysisActivity") | .slot_usage.id.pattern) = ".*"'
'(.classes[] | select(.name == "MetabolomicsAnalysisActivity") | .slot_usage.id.structured_pattern.syntax) = ".*"'
'(.classes[] | select(.name == "MetagenomeAnnotationActivity") | .slot_usage.id.pattern) = ".*"'
'(.classes[] | select(.name == "MetagenomeAnnotationActivity") | .slot_usage.id.structured_pattern.syntax) = ".*"'
'(.classes[] | select(.name == "MetagenomeAssembly") | .slot_usage.id.pattern) = ".*"'
'(.classes[] | select(.name == "MetagenomeAssembly") | .slot_usage.id.structured_pattern.syntax) = ".*"'
'(.classes[] | select(.name == "MetagenomeSequencingActivity") | .slot_usage.id.pattern) = ".*"'
'(.classes[] | select(.name == "MetagenomeSequencingActivity") | .slot_usage.id.structured_pattern.syntax) = ".*"'
'(.classes[] | select(.name == "MetaproteomicsAnalysisActivity") | .slot_usage.id.pattern) = ".*"'
'(.classes[] | select(.name == "MetaproteomicsAnalysisActivity") | .slot_usage.id.structured_pattern.syntax) = ".*"'
'(.classes[] | select(.name == "MetatranscriptomeActivity") | .slot_usage.id.pattern) = ".*"'
'(.classes[] | select(.name == "MetatranscriptomeActivity") | .slot_usage.id.structured_pattern.syntax) = ".*"'
'(.classes[] | select(.name == "MetatranscriptomeAnnotationActivity") | .slot_usage.id.pattern) = ".*"'
'(.classes[] | select(.name == "MetatranscriptomeAnnotationActivity") | .slot_usage.id.structured_pattern.syntax) = ".*"'
'(.classes[] | select(.name == "MetatranscriptomeAssembly") | .slot_usage.id.pattern) = ".*"'
'(.classes[] | select(.name == "MetatranscriptomeAssembly") | .slot_usage.id.structured_pattern.syntax) = ".*"'
'(.classes[] | select(.name == "NomAnalysisActivity") | .slot_usage.id.pattern) = ".*"'
'(.classes[] | select(.name == "NomAnalysisActivity") | .slot_usage.id.structured_pattern.syntax) = ".*"'
'(.classes[] | select(.name == "OmicsProcessing") | .slot_usage.id.pattern) = ".*"'
'(.classes[] | select(.name == "OmicsProcessing") | .slot_usage.part_of.pattern) = ".*"'
'(.classes[] | select(.name == "OmicsProcessing") | .slot_usage.has_input.pattern) = ".*"'
'(.classes[] | select(.name == "OmicsProcessing") | .slot_usage.has_output.pattern) = ".*"'
'(.classes[] | select(.name == "OmicsProcessing") | .slot_usage.id.structured_pattern.syntax) = ".*"'
'(.classes[] | select(.name == "ReadBasedTaxonomyAnalysisActivity") | .slot_usage.id.pattern) = ".*"'
'(.classes[] | select(.name == "ReadBasedTaxonomyAnalysisActivity") | .slot_usage.id.structured_pattern.syntax) = ".*"'
'(.classes[] | select(.name == "ReadQcAnalysisActivity") | .slot_usage.id.pattern) = ".*"'
'(.classes[] | select(.name == "ReadQcAnalysisActivity") | .slot_usage.id.structured_pattern.syntax) = ".*"'
'(.classes[] | select(.name == "Study") | .slot_usage.id.pattern) = ".*"'
'(.classes[] | select(.name == "Study") | .slot_usage.id.structured_pattern.syntax) = ".*"'
poetry run gen-linkml \
        --format yaml \
        --mergeimports \
        --metadata \
        --no-materialize-attributes \
        --materialize-patterns \
        --useuris \
        --output nmdc_schema/nmdc_schema_accepting_legacy_ids.yaml.temp nmdc_schema/nmdc_schema_accepting_legacy_ids.yaml
nmdc_schema/nmdc_schema_accepting_legacy_ids.yaml.temp
mv nmdc_schema/nmdc_schema_accepting_legacy_ids.yaml.temp nmdc_schema/nmdc_schema_accepting_legacy_ids.yaml
poetry run gen-json-schema \
        --closed nmdc_schema/nmdc_schema_accepting_legacy_ids.yaml > nmdc_schema/nmdc_schema_accepting_legacy_ids.schema.json
poetry run gen-python --log_level ERROR --validate nmdc_schema/nmdc_schema_accepting_legacy_ids.yaml > nmdc_schema/nmdc_schema_accepting_legacy_ids.py # todo doesn't honor --log_level
poetry run test-more-tolerant-schema
id: xxx
type: nmdc:Biosample
associated_studies:
- gold:Gs0114663
env_broad_scale:
  type: nmdc:ControlledIdentifiedTermValue
  term:
    id: ENVO:00010483
    type: nmdc:OntologyClass
    name: freshwater environment
env_local_scale:
  type: nmdc:ControlledIdentifiedTermValue
  term:
    id: ENVO:00010483
    type: nmdc:OntologyClass
    name: freshwater environment
env_medium:
  type: nmdc:ControlledIdentifiedTermValue
  term:
    id: ENVO:00010483
    type: nmdc:OntologyClass
    name: freshwater environment

# keep these in sync between PROJECT_FOLDERS and the includes/excludes for gen-project and test-schema
poetry run gen-project \
        --exclude excel \
        --exclude graphql \
        --exclude jsonld \
        --exclude markdown \
        --exclude proto \
        --exclude shacl \
        --exclude shex \
        --exclude sqlddl \
        --include jsonldcontext \
        --include jsonschema \
        --include owl \
        --include python \
        --include rdf \
        -d project src/schema/nmdc.yaml && mv project/*.py nmdc_schema
WARNING:root:ignoring equals_string=pass as unable to tell if literal
WARNING:root:ignoring equals_string=plate as unable to tell if literal
WARNING:root:ignoring equals_string=plate as unable to tell if literal
WARNING:root:ignoring equals_string=plate as unable to tell if literal
WARNING:root:ignoring equals_string=plate as unable to tell if literal
WARNING:root:ignoring equals_string=dataset_doi as unable to tell if literal
WARNING:root:ignoring equals_string=award_doi as unable to tell if literal
WARNING:root:Null expr in: [None, None] for http://www.w3.org/2002/07/owl#unionOf None
WARNING:root:Null expr in: [None] for http://www.w3.org/2002/07/owl#intersectionOf None
WARNING:root:ignoring equals_string=gas_chromatography as unable to tell if literal
WARNING:root:Multiple owl types {rdflib.term.URIRef('http://www.w3.org/2002/07/owl#Thing'), rdflib.term.URIRef('http://www.w3.org/2000/01/rdf-schema#Literal')}
cp project/jsonschema/nmdc.schema.json  nmdc_schema
# added copying of images and renaming of TEMP.md
cp src/docs/*md docs ; \
cp -r src/docs/images docs ; \
poetry run gen-doc -d docs --template-directory src/doc-templates src/schema/nmdc.yaml
None
mkdir -p docs/javascripts
poetry run cp src/scripts/*.js docs/javascripts/
poetry run gen-linkml \
        --format yaml \
        --materialize-patterns \
        --no-materialize-attributes \
        --output project/nmdc_materialized_patterns.yaml src/schema/nmdc.yaml
project/nmdc_materialized_patterns.yaml
poetry run gen-json-schema \
        --closed \
        --top-class Database project/nmdc_materialized_patterns.yaml > project/nmdc_materialized_patterns.schema.json
cp project/nmdc_materialized_patterns.schema.json nmdc_schema/nmdc_materialized_patterns.schema.json
cp project/nmdc_materialized_patterns.yaml nmdc_schema/nmdc_materialized_patterns.yaml
poetry run gen-linkml \
        --format yaml \
        --no-materialize-attributes \
        --no-materialize-patterns \
        --output project/nmdc_schema_merged.yaml src/schema/nmdc.yaml
project/nmdc_schema_merged.yaml
cp project/nmdc_schema_merged.yaml nmdc_schema/nmdc_schema_merged.yaml
# just can't seem to tell pyproject.toml to bundle artifacts like these
#   so reverting to copying into the module
cp sssom/gold-to-mixs.sssom.tsv nmdc_schema/gold-to-mixs.sssom.tsv
poetry run python -m unittest discover


.

....s

id: nmdc:ILLEGAL_ID_VAL
type: nmdc:ChromatographicSeparationProcess
ordered_mobile_phases:
- has_solution_components:
  - compound: deionized_water
    type: nmdc:SolutionComponent
  - compound: methanol
    type: nmdc:SolutionComponent
    concentration:
      type: nmdc:QuantityValue
      has_numeric_value: 10.0
      has_unit: '%'
  type: nmdc:Solution
  volume:
    type: nmdc:QuantityValue
    has_numeric_value: 100.0
    has_unit: mL
stationary_phase: C8

.

Extraction(id='nmdc:ILLEGAL_ID_VAL', type='nmdc:Extraction', name=None, description=None, alternative_identifiers=[], has_input=['nmdc:ILLEGAL_ID_VAL'], has_output=['nmdc:ILLEGAL_ID_VAL'], instrument_used=[], processing_institution=None, protocol_link=None, start_date=None, end_date=None, qc_status=None, qc_comment=None, has_failure_categorization=[], extractant=Solution(has_solution_components=[SolutionComponent(compound='deionized_water', type='nmdc:SolutionComponent', concentration=None), SolutionComponent(compound='deionized_water', type='nmdc:SolutionComponent', concentration=QuantityValue(type='nmdc:QuantityValue', has_raw_value=None, was_generated_by=None, has_maximum_numeric_value=None, has_minimum_numeric_value=None, has_numeric_value=10.0, has_unit='%'))], type='nmdc:Solution', volume=QuantityValue(type='nmdc:QuantityValue', has_raw_value=None, was_generated_by=None, has_maximum_numeric_value=None, has_minimum_numeric_value=None, has_numeric_value=100.0, has_unit='mL')), extraction_target=None, input_mass=None, volume=None)
id: nmdc:ILLEGAL_ID_VAL
type: nmdc:Extraction
has_input:
- nmdc:ILLEGAL_ID_VAL
has_output:
- nmdc:ILLEGAL_ID_VAL
extractant:
  has_solution_components:
  - compound: deionized_water
    type: nmdc:SolutionComponent
  - compound: deionized_water
    type: nmdc:SolutionComponent
    concentration:
      type: nmdc:QuantityValue
      has_numeric_value: 10.0
      has_unit: '%'
  type: nmdc:Solution
  volume:
    type: nmdc:QuantityValue
    has_numeric_value: 100.0
    has_unit: mL

......

.ss.
----------------------------------------------------------------------
Ran 17 tests in 15.546s

OK (skipped=3)
# the need for this may be eliminated by adding mandatory pattern materialization to gen-json-schema
poetry run gen-linkml \
        --output project/nmdc_schema_generated.yaml \
        --materialize-patterns \
        --no-materialize-attributes \
        --format yaml src/schema/nmdc.yaml
project/nmdc_schema_generated.yaml
mkdir -p examples/output
poetry run linkml-run-examples \
        --schema project/nmdc_schema_generated.yaml \
        --input-directory src/data/valid \
        --counter-example-input-directory src/data/invalid \
        --output-directory examples/output > examples/output/README.md
(nmdc-schema-py3.10) mark@mark-NUC10i7FNH:~/gitrepos/berkeley-schema-fy24$

