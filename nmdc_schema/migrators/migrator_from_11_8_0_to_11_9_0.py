from nmdc_schema.migrators.migrator_base import MigratorBase

class Migrator(MigratorBase):
    r"""Migrates a database between two schemas."""

    _from_version = "11.8.0"
    _to_version = "11.9.0"
    wfe_mappings = {}
    data_objects_mapping = {}

    def upgrade(self) -> None:
        r"""Migrates the database from conforming to the original schema, to conforming to the new schema.
        This migrator addresses issue https://github.com/microbiomedata/nmdc-schema/issues/1727.
        This will deprecate nmdc:MetagenomeSequencing type within the workflow_execution_set collection. Fields from the deprecated records will be migrated to the related DataGeneration records.
        
        The following fields will be migrated from the WorkflowExecution records to the DataGeneration records:
        - started_at_time
        - ended_at_time
        - has_output
        
        Additionally, it will properly link the DataObjects to the associated DataGeneration records through the was_generated_by field.

        Important links to note:
        - The `was_informed_by` field in the WorkFlowExecution records will be used to link the DataGeneration records that were created to replace the deprecated WorkflowExecution records.
        - The `has_output` field in the WorkFlowExecution records will be used to identify the DataObjects that were generated by the records of interest, and will be added to the DataGeneration records.
        - the 'was_generated_by' field in the DataObjects will be updated to point to the corresponding DataGeneration records.

        """
        self.adapter.do_for_each_document("workflow_execution_set", self.store_we_ms_fields)
        self.adapter.process_each_document("data_object_set", [self.link_do_to_dg])
        self.adapter.process_each_document("data_generation_set", [self.migrate_fields_to_dg])

    def store_we_ms_fields(self, workflow_execution_record: dict) -> None:
        r"""
        For each workflow execution record that is of type MetagenomeSequencing, gather the following fields to fill the corresponding DataGeneration record:
        - started_at_time
        - ended_at_time
        - has_output (used to fill the has_output field in the DataGeneration record, and used to link the DataObjects to the DataGeneration record)
    
        """
        if workflow_execution_record.get("type") == "nmdc:MetagenomeSequencing":
            ms_id = workflow_execution_record.get("id")
            dg_id = workflow_execution_record.get("was_informed_by")
            data_object = workflow_execution_record.get("has_output", [])
            dg_record = {
                "ms_id": ms_id,
                "started_at_time": workflow_execution_record.get("started_at_time"),
                "ended_at_time": workflow_execution_record.get("ended_at_time"),
                "has_output": data_object,
            }
            self.data_objects_mapping[data_object[0]] = workflow_execution_record.get("was_informed_by")
            # Add the dict to the wfe_mappings
            self.wfe_mappings[dg_id] = dg_record

    def link_do_to_dg(self, data_object_record: dict) -> dict:
        r"""
        For each data object, link it to the corresponding DataGeneration record through the was_generated_by field using the data_objects_mapping.
        """
        #create a list of the data object ids that we will be adding to
        data_object_ids = self.data_objects_mapping.keys()
        # get the id of the current data object
        do_id = data_object_record.get("id")
        # Check if the data object is an object of interest
        if do_id in data_object_ids:
            # Check if the data object already has a was_generated_by field
            if not data_object_record.get("was_generated_by"):
                data_object_record["was_generated_by"] = self.data_objects_mapping.get(do_id)
            else:
                # If it already has a was_generated_by field, we do not want to overwrite it
                self.logger.warning(f"Data object {do_id} already has a was_generated_by field, skipping update.")
        return data_object_record

    def migrate_fields_to_dg(self, data_generation_record: dict) -> dict:
        r"""
        Migrate the fields from the workflow execution record to the DataGeneration record.
        """
        # Get the target ids from the wfe_mappings
        target_ids = list(self.wfe_mappings.keys())
        dg_record_id = data_generation_record.get("id")

        # Check if the data generation record is one of the target ids
        if dg_record_id in target_ids:
            # get the corresponding mapping from wfe_mappings
            wfe_map = self.wfe_mappings[dg_record_id]
            dg_has_output = data_generation_record.get("has_output",[])
            wfe_map_has_output = wfe_map.get("has_output", [])
            # Migrate the time fields
            data_generation_record["start_time"] = wfe_map.get("started_at_time", None)
            data_generation_record["end_time"] = wfe_map.get("ended_at_time", None)
            
            # Migrate the has_output field
            if not dg_has_output:
                data_generation_record["has_output"] = wfe_map_has_output

            elif dg_has_output and not any(item in dg_has_output for item in wfe_map_has_output):
                data_generation_record["has_output"] = data_generation_record["has_output"] + wfe_map_has_output
                
        return data_generation_record




# data_generation_record = {
#       "id": "nmdc:omprc-11-8yy07g21",
#       "name": "Metatranscriptome of feshwater microbial communities from Michigan, USA - augustacreek_2019_sw_WHONDRS-S19S_0067",
#       "has_input": [
#         "nmdc:bsm-11-fx02pd04"
#       ],
#       "add_date": "2020-08-07T00:00:00",
#       "mod_date": "2020-08-07T00:00:00",
#       "ncbi_project_name": "Metatranscriptome of feshwater microbial communities from Michigan, USA - augustacreek_2019_sw_WHONDRS-S19S_0067",
#       "principal_investigator": {
#         "has_raw_value": "Kelly Wrighton",
#         "email": "kwrighton@gmail.com",
#         "name": "Kelly Wrighton",
#         "type": "nmdc:PersonValue"
#       },
#       "processing_institution": "JGI",
#       "type": "nmdc:NucleotideSequencing",
#       "gold_sequencing_project_identifiers": [
#         "gold:Gp0503318"
#       ],
#       "analyte_category": "metatranscriptome",
#       "associated_studies": [
#         "nmdc:sty-11-5tgfr349"
#       ],
#       "instrument_used": [
#         "nmdc:inst-14-mr4r2w09"
#       ]
#     }

# workflow_execution_record = {
#       "id": "nmdc:wfmsa-11-kd2tsp04.1",
#       "name": "Sequencing Activity for nmdc:wfmsa-11-kd2tsp04.1",
#       "started_at_time": "2023-03-07T23:08:31.866680+00:00",
#       "ended_at_time": "2023-03-07T23:08:31.866706+00:00",
#       "was_informed_by": "nmdc:omprc-11-8yy07g21",
#       "execution_resource": "JGI",
#       "git_url": "https://github.com/microbiomedata/RawSequencingData",
#       "has_input": [
#         "nmdc:bsm-11-fx02pd04"
#       ],
#       "has_output": [
#         "nmdc:dobj-11-nrjyjm33"
#       ],
#       "type": "nmdc:MetagenomeSequencing",
#       "version": "v1.0.0"
#     }

# data_object_record =     {
#       "id": "nmdc:dobj-11-nrjyjm33",
#       "name": "Raw sequencer read data",
#       "description": "Metagenome Raw Reads for nmdc:omprc-11-8yy07g21",
#       "alternative_identifiers": [],
#       "file_size_bytes": 9846194352,
#       "md5_checksum": "3a2b7497e18f251bc33ebb883bdef3fe",
#       "data_object_type": "Metatranscriptome Raw Reads",
#       "url": "https://data.microbiomedata.org/data/nmdc:omprc-11-8yy07g21/nmdc:wfmsa-11-kd2tsp04.1/52442.4.335919.GTAACGAC-GTCGTTAC.fastq.gz",
#       "type": "nmdc:DataObject",
#       "data_category": "instrument_data"
#     }

# if __name__ == "__main__":
#     migrator = Migrator()

#     # Example usage of the migrator

#     print("Workflow Execution Record after migration:")
#     migrator.store_we_ms_fields(workflow_execution_record)
#     print(migrator.wfe_mappings)

#     print("Data Object Record after linking:")
#     print(migrator.link_do_to_dg(data_object_record))

#     print("Data Generation Record after migration:")
#     print(migrator.migrate_fields_to_dg(data_generation_record))