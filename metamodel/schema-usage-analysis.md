# Usage Analysis of Non-Imported Schemas

## Schemas NOT Imported by meta.yaml

1. **validation.yaml** (reporting.yaml)
2. **datasets.yaml**
3. **array.yaml**
4. **extended_types.yaml**

## Findings from linkml and linkml-runtime Repos

### 1. validation.yaml (reporting.yaml)

**Status**: ‚úÖ **ACTIVELY USED**

**Usage in linkml repo:**
- Used by the validation framework in `linkml/validator/`
- Referenced in 8+ Python files:
  - `validator/validator.py`
  - `validator/report.py`
  - Multiple validation plugins (jsonschema, shacl, pydantic, etc.)
- The classes `ValidationReport` and `ValidationResult` are used programmatically
- Note: `linkml/validator/report.py` defines Pydantic versions of these classes (not generated from the schema)

**In linkml-runtime:**
- Schema file is present at `linkml_runtime/linkml_model/model/schema/validation.yaml`
- Generated Python model exists at `linkml/reporting/model.py` (autogenerated)

**Purpose**: Data model for validation reports (SHACL-based)

**Recommendation**: ‚ö†Ô∏è **KEEP** - Core to validation infrastructure

---

### 2. array.yaml

**Status**: ‚úÖ **ACTIVELY USED**

**Usage in linkml repo:**
- Used by Pydantic generator: `linkml/generators/pydanticgen/array.py`
- Imports `ArrayExpression` and `DimensionExpression` from linkml-runtime
- Used to generate NumPy-compatible array types in Pydantic models

**In linkml-runtime:**
- Schema file present at `linkml_runtime/linkml_model/model/schema/array.yaml`
- Classes integrated into metamodel runtime (`linkml_runtime.linkml_model.meta`)

**Purpose**: Support for N-dimensional arrays (experimental feature)

**Recommendation**: ‚ö†Ô∏è **KEEP** - Used by Pydantic generator for array support

---

### 3. datasets.yaml

**Status**: ‚ùì **NO USAGE FOUND**

**Usage in linkml repo:**
- No Python imports of `DataPackage` or `DataResource` found
- No documentation references found

**In linkml-runtime:**
- Schema file IS present at `linkml_runtime/linkml_model/model/schema/datasets.yaml`
- But no evidence of programmatic usage

**Purpose**: Data model for dataset metadata (inspired by Frictionless Data)

**Recommendation**: üîç **INVESTIGATE** - May be unused or aspirational

---

### 4. extended_types.yaml

**Status**: ‚ùì **NO EVIDENCE FOUND**

**Usage in linkml repo:**
- No imports found
- No documentation found

**In linkml-runtime:**
- **NOT PRESENT** - Missing from `linkml_runtime/linkml_model/model/schema/`

**Purpose**: Extended numeric types (int8, uint16, float32, etc.) similar to NumPy

**Recommendation**: üóëÔ∏è **CANDIDATE FOR REMOVAL** - Not in runtime, no usage found

---

## Summary Table

| Schema | In Runtime? | Used in linkml? | Recommendation |
|--------|-------------|-----------------|----------------|
| **validation.yaml** | ‚úÖ Yes | ‚úÖ Yes (validator/) | **KEEP** |
| **array.yaml** | ‚úÖ Yes | ‚úÖ Yes (pydanticgen/) | **KEEP** |
| **datasets.yaml** | ‚úÖ Yes | ‚ùå No usage found | **INVESTIGATE** |
| **extended_types.yaml** | ‚ùå NO | ‚ùå No usage found | **REMOVE?** |

## Key Questions for GitHub Discussion

1. **Why aren't validation.yaml and array.yaml imported into meta.yaml?**
   - They're clearly used, but kept separate
   - Is this intentional modularity or an oversight?

2. **What's the intended use of datasets.yaml?**
   - It's in the runtime but has no code references
   - Is it for external adopters? Example schema?

3. **Should extended_types.yaml be removed?**
   - Not in linkml-runtime
   - No usage found
   - Appears to be abandoned

4. **Should validation and array be imported into meta.yaml?**
   - Would make them "official" parts of the metamodel
   - Or should they remain as optional extensions?
